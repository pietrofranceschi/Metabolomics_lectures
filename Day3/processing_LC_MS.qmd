---
title: "Processing LC-MS Metabolomics Data with xcms"
author: "Pietro Franceschi"
format: 
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: true
    footer: pietro.franceschi@fmach.it
---

## What is `xcms`

Framework for processing and visualization of chromatographically separated and single-spectra mass spectral data. 

[xcms](http://www.bioconductor.org/packages/release/bioc/html/xcms.html)

and still growing ...

[RforMassSpectrometry](https://www.rformassspectrometry.org/)

::: {layout-ncol=2}

![](images/compoundDB.png){fig-align="center" width=30%}

![](images/spectra.png){fig-align="center" width=30%}


:::





## Outline {.smaller background-image="images/numbers.jpg"}

* Data analysis, organization and data matrices
* Some thoughts on validation
* Preprocessing and analytical variability
* MS for Dummies
* LC-MS data handling
* Demo & DIY
* Peak Picking in `xcms`
* Demo & DIY
* Retention time correction and features definition
* Demo & DIY
* Dealing with Fragmentation esperiments
* Demo & DIY

## The data matrix

![](images/Matrix.svg){fig-align="center" width=50%}



## The role of Data Analysis


```{r}
library(tidyverse)
library(patchwork)
library(xcms)
library(plotly)
```


Statistics, Bionformatics, Machine Learning, Chemometrics, ..., provide the tools to:

* make science shared and reproducible ... ;-)
* process and organize **big data** into the matrix
* identify the presence of **organization** in the data matrix
* assess the confidence that our result is true "at the population level"


## Examples of Organization


```{r}

a <- tibble(class = rep(c("A","B"), each = 100),
       intensity = c(rnorm(100,10), rnorm(100,11))) %>% 
  ggplot() + 
  geom_jitter(aes(x = class, y = intensity, col = class), width = 0.1) + 
  theme_bw() + 
  theme(aspect.ratio = 1)


b <- tibble(met_a = runif(20,0,10)) %>%
  mutate(noise = rnorm(20)) %>% 
  mutate(met_b = met_a*2 + noise) %>% 
  ggplot() + 
  geom_point(aes(x = met_a, y = met_b), col = "steelblue", size = 2) + 
  theme_bw() + 
  theme(aspect.ratio = 1)


b|a

```

## Fat Data Matrices 

The typical metabolomics data matrix looks like this:

```{r, fig.align = 'center'}
library(reshape2)
random_data <- matrix(rnorm(2000*20), nrow = 20) 

random_data [,1:200] %>% 
  melt() %>%
  ggplot(aes(x = Var2, y = Var1)) + 
  geom_raster(aes(fill=value)) + 
  scale_fill_viridis_c() +
  coord_fixed()+
  theme_void() + theme(legend.position = "none", )
```

Let's take 20 samples and 2000 variables ... and fill the matrix of random numbers

## Correlation coefficients

```{r}
#| fig-height: 6
#| fig-align: center

mycor <- cor(random_data)


hist(mycor[upper.tri(mycor)], col = "steelblue", 
     main = "Pearson Correlation", xlab = "Correlation",
     border = "white")

```

Range of correlations: `r round(range(mycor[upper.tri(mycor)]),2)`


We have relatively large values. Why? 

## False Positives {background-image="images/brain_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}

* Organization can show up only by chance
* These results are *true*, but the hold only for the data we are analyzing now
* Organization is not necessarily science
* Variability causes this
* We need to *validate* our outcomes

:::

## On Validation

* **Statistical Validation**: get brand new samples and see if what we get is still there
* **Domain Validation**: is what I'm getting in keeping with the domain specific body of knowledge? Could I design an experiment to check my hypothesis?

. . .

#### Do we always need statistics?


## By the way ...

* What are the variables measured in a *targeted metabolomics assay?*
* What are the variables measured in an *untargeted LC-MS metabolomics experiment?*
* What are the variables measured in an *untargeted NMR metabolomics experiment?*


## Data hygiene

::: incremental
* Go for a scripting language and forget Excel
* ... at least use a gui pipeline or a web based solution
* Organize data and metadata
* Avoid as much as possible *manual curation*
* Share your data, your scripts, your results
* Go open source
:::


## Get out your data

* Metabolomics data are always stored in "formats" which are specifically developed by instrument vendors
* In the case of MS data several open source standards are available (cdf, mzML, mzIML, ...)

[Proteowizard](https://proteowizard.sourceforge.io/) 

* command line tool
* gui application
* docker with proprietary libraries



## LC-MS For Dummies

![](images/LCMS.jpg){fig-align="center"}




## Analytical Variability in LC-MS: mass

![](images/mass_drift.png){fig-align="center"}


## Analytical Variability in LC-MS: retention time

```{r}

fnames <- list.files("data/apples/","CDF", full.names = TRUE)

apples <- readMSData(fnames, mode = "onDisk") 

```

```{r}
bpi <- apples %>% filterRt(c(250,410)) %>% chromatogram(aggregationFun = "max")
```

```{r}
#| fig-height: 6
#| fig-align: center

plot(bpi, col = "steelblue", main = "BPI")
```



## Analytical Variability in LC-MS: intensity

![](images/Total_ion_current.png){width=100% fig-align="center"}

## Preprocessing

::: incremental
* I call **preprocessing** all the data carpentry steps I do to go from the raw experimental data to the data matrix
* The aim of this process is to compensate for *analytical variability* being able to reliably build a data matrix
* *QC samples* play a big role on that because they are sensitive only to analytical variability
:::

## Uses of QCs {background-image="images/brain_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}

*QCs should be representative of the chemical complexity of your samples*

* correct for retention time shifts
* identify <span style="color: red">reliable</span> variables: 
    * variance in QC should be smaller than in samples
    * they should decrease during dilution
    * ...
* help in correcting for bath effects ...

:::



## LC-MS produces 3D data (rt,mz,I)
![](images/LCMS_data.png){fig-align="center"}

#### Things too look at
* Extracted Ion Trace/Current (EIT/EIC)
* Mass Spectra


## Extracted ion traces

```{r}
#| fig-height: 6
#| fig-align: center

register(SerialParam())
proc_trace <- chromatogram(apples %>% filterRt(c(100,500)), mz = 577.13 + c(-1,1)*0.01)
plot(proc_trace, col = "coral")
```


## Mass Spectra

```{r}

#| fig-height: 6
#| fig-align: center


ms <- apples[[1000]]

tibble(mz =  mz(ms), i = intensity(ms)) %>% 
  ggplot() + 
  geom_segment(aes(x = mz, xend = mz, y = 0, yend = i)) + 
  theme_bw()



```



## Back to Raw data

Always check your results on the raw data

* problems in preprocessing
* bad peaks
* biomarkers
* results hidden in noise


##

::: {layout="[[-1], [1], [-1]]"}
![](images/RStudio.png){fig-align="center"}
:::


# Peak Picking

## Peaks and metabolites: facts {background-image="images/brain_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}
* A metabolite produces peaks in the extracted ion traces of its associated ions
* Different peaks in the same ion chromatograms are associated to different metabolites
* Peaks are not metabolites
* The same peak can slightly move across the injections

### We need methods to automatically find peaks

:::

## MatchedFilter

![](images/matchedFilter.png){width=60% fig-align="center"}


::: footer
Anal Chem 2006 1;78(3):779-87. doi: 10.1021/ac051437y.
:::

## Cent Wave

![](images/cent_wave.png){width=50% fig-align="center"}


::: footer
BMC Bioinformatics 9, 504 (2008). https://doi.org/10.1186/1471-2105-9-504
:::


## Peak Intensity: `into` and `maxo`

![](images/maxointo.png){width=50% fig-align="center"}




## Things to always consider {background-image="images/eye_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}
::: incremental
* Real peaks can be really badly shaped
* You are better than an algorithm ... maybe AI will do well
* Every algorithm has parameters to tune!
* Look to the data!
* Know how the instrument works
* Check what happens to metabolites you know should be there
:::
:::

##

::: {layout="[[-1], [1], [-1]]"}
![](images/RStudio.png){fig-align="center"}
:::

# Retention time correction and feature definition

## ... Just a recap

1. We converted the data files in an open source format (here mzML)
2. We optimized the peak picking parameters working on a representative sample (Qc)
3. We have been running peak picking on the full set of samples
4. We have been saving the output somewhere, just to avoid re-starting from scratch ;-)

## What Next

We have to merge the lists of <span style="color: red">chromatographic peaks</span> into a consensus list of <span style="color: red"> features peaks</span>, which will be the columns of our data matrix

* *chromatographich peaks* what was detected in the individual samples (mz,rt,intensity)
* *features* consensus variables which are *grouping* several peaks coming from the different injections (mz,rt, intensity)

## Grouping 

![](images/grouping.svg){width=60% fig-align="center"}


## Retention time correction

![](images/workflow.svg){width=100% fig-align="center"}

## Dynamic Time Warping

Available in `xcms` trough `obiwarp`

. . .

Mind the power of warping ...

![](images/warping.png){width=100% fig-align="center"}

##

![](images/rt_shift.png){width=100% fig-align="center"}





## Things to always consider {background-image="images/eye_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}
::: incremental
* Aligning samples and not QCs can be tricky
* Some metabolites could not be present in pooled QC (dilutions)
* Sometimes chromatographic peaks are missed
* Always check the data and the known peaks!
* Parameters are easier to tune if you know how the analytics works
:::
:::

## NAsss  NAsss

Even if you do everything well your final data matrix will be full of missing values:

* errors in peak picking
* "absence" of a metabolite in one or more samples (biology)
* that metabolite is below the detection limit (analytics)

<hr>

. . .

* missing at random
* missing not at random



##

::: {layout="[[-1], [1], [-1]]"}
![](images/RStudio.png){fig-align="center"}
:::


# Bonus Section: fragmentation data

## Annotation and MS {background-image="images/brain_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}

::: incremental
* At the end of the journey we would like to work on *metabolites* or *pathways* and not on features
* We know that **annotation** is the most challenging step of all the business
* The more we know about the structure of our ions the better it is
* Database of standards, web resources, chemoinformatics, ...
* **Fragmentation patterns are extremely useful**

:::

:::

## MS/MS and DDA

*DDA*: data dependent acquisition


![](images/tandemMS.jpg){width=60% fig-align="center"}


##

::: {layout="[[-1], [1], [-1]]"}
![](images/RStudio.png){fig-align="center"}
:::
