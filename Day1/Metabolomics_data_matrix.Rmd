---
title: "Metabolomics Data Matrix"
author: "Pietro Franceschi"
output: 
  ioslides_presentation:
    css: "../mycss.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(tidyverse)
```



## Many variables in many samples

As in all _omic_ experiments, a metabolomic assay allows to measure a large number of _variables_(properties) in a (hopefully) reasonably large number of samples.

<br>
<hr>
<br>

~~... what are the variables ...~~

> 1. In a targeted metabolomics investigation?
> 2. In an untargeted MS based metabolomics analysis? 
> 3. In an untargeted NMR based metabolomics assay?

	
## Number of variables | place your guess {.build}

> * Targeted metabolomics investigation
> * ~~from 10 to 300~~
> * Unargeted metabolomics investigation
> * ~~from 1000 to 30000~~ 


## Data Matrix

```{r, echo=FALSE, fig.align='center', out.width="60%"}
include_graphics("../images/Matrix.svg")
```


## {.flexbox .vcenter}

~~**The objective of our analysis is to find "organization" inside the matrix**~~


~~**Our organization should be also statistically robust**~~


## Organization: Correlations

```{r}

# --- Parameters ---
rho_target <- 0.8  # Desired correlation coefficient
n <- 150           # Number of data points

# Set seed for reproducibility
set.seed(42)

# 1. Generate Correlated Data
# X is a standard normal variable
X <- rnorm(n)
# Epsilon is independent standard normal noise
Epsilon <- rnorm(n)

# Y is created such that the correlation between X and Y is approximately rho
# Formula: Y = rho * X + sqrt(1 - rho^2) * Epsilon
Y <- rho_target * X + sqrt(1 - rho_target^2) * Epsilon

# Create a data frame
data_plot <- data.frame(X = X, Y = Y)

# Calculate the actual correlation for the plot label
actual_rho <- cor(data_plot$X, data_plot$Y)

# 2. Create the Plot using ggplot2
ggplot(data_plot, aes(x = X, y = Y)) +
  # Add scatter points
  geom_point(color = "#0072B2", alpha = 0.7, size = 3) + # Blue points
  # Add a linear regression line (geom_smooth(method = "lm"))
  geom_smooth(method = "lm", se = TRUE, color = "#D55E00", linetype = "solid", linewidth = 1) + # Orange regression line
  # Customize plot theme and labels
  theme_minimal(base_size = 14) +
  labs(
    x = "Variable X",
    y = "Variable Y"
  ) +
  # Customize title alignment and font
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5, size = 12))

```


## Organization: Biomarkers

```{r}
set.seed(123) # For reproducibility
n <- 50 # Number of observations per group

# Group 1 (Lower Mean)
group1_data <- rnorm(n, mean = 10, sd = 2) 

# Group 2 (Higher Mean - designed to be significantly different)
group2_data <- rnorm(n, mean = 13, sd = 2) 

# Create the final data frame
data_sig <- data.frame(
  Group = factor(c(rep("Control", n), rep("Treatment", n))),
  Variable_A = c(group1_data, group2_data)
)



# --- 3. Create the Jitter Plot with Boxplots and Significance ---
ggplot(data_sig, aes(x = Group, y = Variable_A, fill = Group)) +
  
  # A. Boxplot (to show quartiles, median, and outliers)
  geom_boxplot(width = 0.3, alpha = 0.5, outlier.shape = NA) +
  
  # B. Jitter Plot (to show individual data points)
  geom_jitter(width = 0.2, alpha = 0.7, size = 2) +
  
  # D. Customization
  scale_fill_manual(values = c("Control" = "#E69F00", "Treatment" = "#56B4E9")) + # Colorblind-friendly colors
  labs(
    x = "Group",
    y = "Variable A (Continuous)"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", hjust = 0.5))
```




## Variables are not independent {.smaller}

* Biological relations
* Chemical/Analytical reasons

```{r fig.align='center', out.width="100%"}
x <- 1:20
y <- x*2 + rnorm(20,0,3)
par(pty="s")
plot(x,y, main = "Correlation", xlab = "Var1", ylab = "Var2", cex = 1, col = "coral", pch = 19)
```

---



```{r, echo=FALSE, fig.align='center', out.width="50%"}
include_graphics("../images/important.png")
```

<br>

<div style="background-color:#73AD21;padding:20px;border-radius: 15px;color:black;text-align: center;">
  <p>Analytical correlation is always stronger than the biological one!</p>
</div>

<br>

*The correlation structure of your matrix is often not really informative about biology*


## Rows (samples) are often dependent

The design of the study can result in a ~~multilevel hierarchical structure~~  of the samples which violate independence. In other words some samples are "by construction" associated and share something in common

~~**Examples**~~

1. Repeated measures of the same individual
2. Subpopulations
3. Different site, different day, ...

## Data Matrix size

In the typical "happy" statistical context, the number of variable we measure is smaller than the number of samples. 

In _omics_ the number of variables normally outperforms the number of samples
<br>
<br>
~~*FAT DATA MATRIX*~~
```{r fig.align='center', fig.height=4, fig.width=12, out.width="100%"}
mymat <- matrix(rnorm(20*300), nrow = 20)
image(t(mymat), asp = 20/300, xlab = "", ylab = "", axes = FALSE)
# Add closer x label
mtext("Variables", side = 1, line = -3)  # smaller line = closer

# Add closer y label
mtext("Samples", side = 2, line = 0)
```

## Univariate approach

The **Univariate** approach considers each variable separately and it applies "standard" statistical tools to spot the more **interesting** variables

1. Statistical testing 
2. Linear modeling (`lm`, `glm`, ...)
3. ANOVAs
4. Hierarchical Modeling

```{r fig.align='center', fig.height=2.5, fig.width=6, out.width="60%"}
mymat <- matrix(rnorm(20*100), nrow = 20)
par(mar=rep(0, 4), xpd = NA) 
image(t(mymat), asp = 20/100, xaxt='n', ann=FALSE, yaxt='n', bty="n")
rect(xleft = 0.5, xright = 0.51, ybottom = -0.1, ytop = 1.1, border = "steelblue", lwd = 2)
rect(xleft = 0.3, xright = 0.31, ybottom = -0.1, ytop = 1.1, border = "steelblue", lwd = 2)
rect(xleft = 0.7, xright = 0.71, ybottom = -0.1, ytop = 1.1, border = "steelblue", lwd = 2)
```

## Where is the problem: Multiple testing

* We measure many variables (features,metabolites) in the same set of samples
* We run a battery of statistical tests looking for the significance of what we see in the individual variables 
* **We ask ourselves if at least one test is significant in the overall set of tests**

<br>
<hr>

~~We run individual tests, but we have question about the full set of variables ...~~


## Multivariate approach

Each samples is represented as a point in the multidimensional variable space. The dataset is a **cloud** of points in that space.

The size of the space equals the number of variables we are measuring. **Multivariate methods** (PCA, PLS, ASCA, ...) are able to exploit the correlation between the variables to highlight/extract the organization of the data

```{r, echo=FALSE, fig.align='center', out.width="40%"}
include_graphics("../images/Coord_planes_color.svg")
```

## Why multivariate ...

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=5, fig.height=6, out.width="50%"}
library(tidyverse)

# Function to generate points on an ellipse
generate_ellipse <- function(center = c(0, 0), axes = c(1, 0.5), angle = 0, n_points = 100) {
  theta <- seq(0, 2 * pi, length.out = n_points)
  # Parametric ellipse before rotation
  x <- axes[1] * cos(theta)
  y <- axes[2] * sin(theta)
  # Rotation matrix
  rot <- matrix(c(cos(angle), -sin(angle), sin(angle), cos(angle)), nrow = 2)
  rotated <- t(rot %*% rbind(x, y))
  # Translate to center
  data.frame(
    x = rotated[, 1] + center[1],
    y = rotated[, 2] + center[2]
  )
}

# Create two ellipses
ellipse1 <- generate_ellipse(center = c(-1.5, 0), axes = c(2, 1), angle = pi / 6)
ellipse1$group <- "Ellipse 1"

ellipse2 <- generate_ellipse(center = c(1.5, 1), axes = c(2, 1), angle = pi / 6)
ellipse2$group <- "Ellipse 2"

# Combine into one data frame
ellipses <- rbind(ellipse1, ellipse2)

# Plot
ggplot(ellipses, aes(x = x, y = y, fill = group, col = group)) +
  geom_path(size = 1.2) +
  geom_polygon(alpha = 0.7) + 
  geom_text(aes(x = -1.5, y = 0, label = "A"), col = "black") + 
  geom_text(aes(x = 1.5, y = 1, label = "B"), col = "black") + 
  xlab("Var 1") + 
  ylab("Var 2") + 
  coord_equal() +
  theme_bw() +
  theme(legend.position = "none", aspect.ratio = 1)
```

Group separation is clearer in the 2d space ...

## Multivariate


~~**PRO**~~ ðŸ˜€

1. Potentially more powerful
2. Explicit use of variable correlation
3. No issues with multiple testing

<hr>

~~**CONS**~~ ðŸ˜ž


1. Chance correlations in fat matrices
2. Empty Space
3. Difficult to embed hierarchical structure

## Univariate


~~**PRO**~~ ðŸ˜€


1. Statistical modeling is there!
2. Interpretable by construction

<hr>

~~**CONS**~~ ðŸ˜ž


1. Multiple testing
2. The structure of the data creates redundancy
3. Assumptions for parametric (and non parametric) approaches are often not fulfilled


## The course of dimensionality

```{r fig.align='center', fig.height=2.5, fig.width=8, out.width="100%"}
set.seed(123)

par(mfrow = c(1,3))
par(pty="s")
plot(y = rep(0,10), x = runif(10,0,10), xaxt='n', yaxt='n', bty="n", xlim = c(-1,11), 
     main = "10 points 1D", xlab = "", ylab = "", col = "#FFA50060", cex = 2, pch  =19)
arrows(x0 = 0 , y0 = 0, x1 = 11)

par(pty="s")
plot(y = runif(10,0,10), x = runif(10,0,10), xlab = "D1", ylab = "D2", main = "10 points 2D", col = "#FFA50060", cex = 2, pch =19)


plot(y = runif(100,0,10), x = runif(100,0,10), xlab = "D1", ylab = "D2", main = "100 points 2D", col = "#FFA50060", cex = 2, pch  =19)

```

1. To fill the space the number of points is not linear with the number of dimensions
2. Already with 10 samples the 2d plot looks empty
3. Can you imagine 20 samples in 10000 dimensions? ;-)

 






