---
title: "Statistical Testing and Effect Size"
author: "Pietro Franceschi" 
output: 
  ioslides_presentation:
    css: "../mycss.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(knitr)
library(tidyverse)
library(MASS)
```



## The BIG question


<div style="border: 2px solid #e74c3c; background-color: #fdecea; padding: 10px; border-radius: 5px;">
  ⚠️ <strong>The question:</strong> <br> Is what I’m observing **true beyond my sample**. Can I draw general conclusions from a limited set samples?
</div>

<br><br>


In presence of variability, there will  always be the possibility that what I observe in my data cannot be generalized at the population level.

* measure more sample
* validate
* give a measure of my **confidence** on the results


## Statistical testing

Due to variability, it is impossible to get **certain** answers from an experiment. The best one can due is to try to **quantify the level of confidence**.

Statistical testing is a procedure which allows us to quantify this level of confidence

## The concept 

1. Suppose that what we observe is the result of chance alone (Null Hypothesis - H0)
2. Use statistics to calculate the probability of getting at least what we observe under H0 (by chance!) (*p-value*)
3. Set a threshold of reasonable confidence (0.05,0.01, ...)

---

```{r, echo=FALSE, fig.align='center', out.width="100%"}
include_graphics("../images/pvalueworship.png")
```

## Example: lowering cholesterol {.build}

>* Suppose that the level of cholesterol in the population is normally distributed with mean 200 and standard deviation 50
>* We claim that a new secret drug we recently invented reduces **significantly** the cholesterol level in the population
>* To prove that we get a group of 50 people, we treat them with the drug and we measure their average cholesterol level.  This mean turns out to be **193**.
>* Is this pilot study supporting my claim ? i.e. is the ~~difference between 193 and 200 significant~~?

## Let's test that! {.build}

>1. Suppose that the drug has no effect (H0) ... but then my 50 people are a random drawing from the population
>2. Calculate the distribution of the mean level of cholesterol in groups of 50 people coming from the population.(mind the gap! ... this is not the distribution of cholesterol in the population!)
>3. Calculate the probability of obtaining less than **193** from this distribution (*p-value*)
>4. Reject the H0 if the p-value is lower than the selected threshold (typically 0.05)

## Let's plot it!

```{r out.width="90%", fig.align='center'}

set.seed(123)
means50 <- rep(0,100)

for(i in (1:100)){
  means50[i] <- mean(rnorm(50,200,50))
}

mycols <- rep("#C8081570",100)
mycols[means50 < 193] <- "#377eb870"

plot(x = 1:100, means50, ylim = c(150, 250), pch = 19, col = mycols, 
     ylab = "mean of 50 individuals", xlab = "Replicated sampling from the population")
abline(h = 193, col = "steelblue", lty = 2)
abline(h = 200, col = "darkred")

```

## What we see {.build}

>* The means of the different groups are different
>* The distribution of the means is nicely centered around the population mean!
>* The blue line represents the mean of my sample 50 people (193!)
>* The blue dots are "random" draws from the population which show an average level of cholesterol lower than the one we observed
>* For blue dots we observe less than 193 by chance
>* Apparently getting at least that value only by chance is not extremely unlikely ... 14 blue dots out 100 (p = 0.14 !)
>* ~~I cannot reject H0 at the 0.05 level ... ~~


## More on this ...{.build}

So you see ... we need a **probability** and we also need a **threshold** (0.05)

<br>

The correct wording in my paper should be 

*" ... the results are not statistically significant at the 0.05 level of confidence"* ... 

~~but they are significant at the 0.15 level! ~~



## More samples! {.smaller}

I'm stubborn, so I'm convinced that the drug is really working. We redo the same study with a test group of **500** people and we observe another time an average level of 193 ...

```{r out.width="70%", fig.align='center'}
means50 <- rep(0,50)

for(i in (1:50)){
  means50[i] <- mean(rnorm(500,200,50))
}


mycols <- rep("#C8081570",50)
mycols[means50 < 193] <- "#377eb870"

plot(x = 1:50, means50, ylim = c(180, 220), pch = 19, col = mycols, 
     ylab = "mean of 50 individuals", xlab = "Replicated sampling from theoretical population")
abline(h = 193, col = "steelblue", lty = 2)
abline(h = 200, col = "darkred")

```

~~Magic! Now it is significant at the 0.05!  No more blue dots! So it is extremely unlikely to get an average cholesterol level of 193 in a group of 500 people if the drug has no lowering effect~~


## Take home messages


```{r, echo=FALSE, fig.align='center', out.width="50%"}
include_graphics("../images/important.png")
```

<br>

* The choice of a ~~threshold (here 0.05) for statistical significance is arbitrary~~
* With more samples we can "see" smaller differences
* We are never sure!
* Is statistical significance the only thing we are looking for?



## Back to our magic drug ...

Unfortunately it turns out that our drug is not so good ... apparently it reduces the cholesterol only of 0.01%

```{r fig.align='center', out.width="70%"}

samp_serie <- rep(c(5,50,500,5000,50000), each = 100)
group_means <- rep(0,length(samp_serie))

for(i in 1:length(samp_serie)){
  group_means[i] <- mean(rnorm(samp_serie[i],200,50))
}

mycols <- rep("#C8081570", length(samp_serie))
mycols[group_means < 198] <- "#377eb870"


plot(x = 1:length(samp_serie), group_means, ylim = c(150, 250), pch = 19, col = mycols, cex = 0.5,
     ylab = "mean of n individuals", xlab = "Replicated sampling from theoretical population", xaxt="n")
abline(h = 198, col = "steelblue", lty = 2)
abline(h = 200, col = "darkred")
abline(v = c(0,100,200,300,400), col = "gray80")
text(x = c(0,100,200,300,400), y = rep(220,5), labels = c("5","50","500","5000","50000"), pos = 4)

```

## Is a low *p-value* the only thing we need? {.build}

>* Is a reduction of 0.01% really useful/relevant?
>* Big number of samples will make tiny differences statistically significant!
>* Statistical significance does not mean biological/agronomic/medical relevance
>* The *p-value* alone cannot be used to judge the relevance of a research ...


## Erroneous ...

* _p-values_ deals with probability of obtaining by chance, not with the strength of an effect
* strong effects with low variability **will** result in low _ps_
* the reverse is not necessarily true!
* "look, I have a low _p-value_!" is not the only thing to look for

## Measuring the _effect size_

```{r out.width= "100%", fig.align='center'}
## Standard normal distribution:

xvalues <- data.frame(x = c(-20, 20))

## add a second normal curve
normal1 <- function(x){
  dnorm(x, mean = -15, sd = 2)
}

normal2 <- function(x){
  dnorm(x, mean = -13, sd = 2)
}

normal3 <- function(x){
  dnorm(x, mean = 5, sd = 2)
}

normal4 <- function(x){
  dnorm(x, mean = 15, sd = 2)
}



xvalues %>% ggplot(aes(x = x)) + 
  stat_function(fun = normal1, lwd = 1, col = "darkblue") + 
  stat_function(fun = normal1, geom = "area", fill = "steelblue", alpha = 0.5) +
  stat_function(fun = normal2, lwd = 1, col = "darkred") + 
  stat_function(fun = normal2, geom = "area", fill = "red", alpha = 0.5) +
  stat_function(fun = normal3, lwd = 1, col = "darkblue") + 
  stat_function(fun = normal3, geom = "area", fill = "steelblue", alpha = 0.5) +
  stat_function(fun = normal4, lwd = 1, col = "darkred") + 
  stat_function(fun = normal4, geom = "area", fill = "red", alpha = 0.5) +
  geom_hline(yintercept = 0, lwd = 1) + xlab("") + ylab("") + 
  geom_text(x = -14, y = 0.25, label = "Small Effect") + 
  geom_text(x = 10, y = 0.25, label = "Large Effect") + 
  theme_light() + 
  ylim(c(0,0.3)) +
  theme(aspect.ratio = 0.3)


```

## Notes

1. The difference in means is not sufficient
2. The measure should take into account of the variability
3. The variability of the population not the one of he sampling distribution ;-)

<hr>

The _fold change_ is **not**  a good measure of the effect size ...


## Cohen's d

$$
d = \frac{\bar{x}_{1} - \bar{x}_{2}}{s}
$$

Where

* $\bar{x}$ are the estimates of the population means
* $s$ is the estimate of the population standard deviation (pooled)



## Let's _see_

- 2 populations: $\mu_{1}=5$, $\mu_{2}=10$, $\sigma=5$
- _t-test_ to test the difference
- different sample sizes


```{r fig.align='center', out.width="70%"}
library(effsize)
library(tidyverse)

## We start with two gaussians @0 and @5 with sd of 5
## for a set of different sample sizes we calculate 100 saplings and for each one p values and cohen d



x <- tibble(size = c(3,5,20,50,100))

## now we create the dataset

x <- x %>% 
  mutate(
    g1 = map(size, function(s) {
      out <- matrix(0,nrow = s, ncol = 100)
      for(i in 1:s){
        out[i,] <- rnorm(100,0,5)
      }
      out
    }),
    g2 = map(size, function(s) {
      out <- matrix(0,nrow = s, ncol = 100)
      for(i in 1:s){
        out[i,] <- rnorm(100,5,5)
      }
      out
    })
  ) 
    
  ## Now we calculate the pvalues


x <- x %>% 
  mutate(ps = map2(g1,g2, function(x,y){
    ps <- rep(0,ncol(x))
    for(i in 1:ncol(x)){
      ps[i] <- t.test(x[,i],y[,i])$p.value
    }
    ps
  }))

## Now the cohen's d

x <- x %>% 
  mutate(ds = map2(g1,g2, function(x,y){
    ds <- rep(0,ncol(x))
    for(i in 1:ncol(x)){
      ds[i] <- cohen.d(x[,i],y[,i])$estimate
    }
    ds
  }))


x %>% 
  unnest(c("ps","ds")) %>%
  mutate(size = factor(size)) %>% 
  dplyr::select(size,ps,ds) %>% 
  pivot_longer(-size) %>% 
  ggplot() + 
  geom_jitter(aes(x = size, y = value), width = 0.2, col = "steelblue", alpha = 0.7) +
  geom_hline(aes(yintercept = if_else(name == "ds",-1,0.05)), col  ="red", lty = 2) +
  facet_wrap(~name, scales = "free") + 
  xlab("Sample Size") + 
  theme_light() + 
  theme(aspect.ratio = 0.7)
  
```

## Notes

* With three samples variability is large
* Also the possibility of calling non significant the difference is large
* Even the effect size does not tell to me if something is relevant!


