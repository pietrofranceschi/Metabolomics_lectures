---
title: "Stratified Random Sampling"
author: "Pietro Franceschi"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = FALSE)
library(tidyverse)
```


## Intro

During the presentation I affirmed that in presence of known subpopulations **stratified random sampling** is able to give a more accurate estimate of the properties of my reference population. Let's check my statement ...

## The question
Suppose that I'm interested in estimating the average height in a population of 10000 people and that I know that out of them 8000 are males and 2000 are females. To create my population I use the following properties: 

* Males: mean = 180 cm, sd = 10 cm
* Females: mean = 150 cm, sd = 10 cm

## Running the simulations

First of all I create my population

```{r}
## separate tibbles
males <- tibble(gender = "M", height = rnorm(8000,180,10))
females <- tibble(gender = "F", height = rnorm(2000,150,10))

## merge everything in a df
mypop <- males %>% 
  bind_rows(females)
```


Just for fun let's give a look 

```{r}
mypop %>% 
  ggplot() + 
  geom_histogram(aes(x = height, fill = gender), col = "white",  alpha = 0.4, position = "identity")  +
  theme_light()
```
Ok, we see what we expect, the two groups are different, and there is an unbalancing.


## The problem

Ok suppose now that I'm interested in estimating well the population mean. In my case this parameter is known ...

```{r}
pop_mu <- mean(mypop$height)
pop_mu
```

In the plt it stays there ...

```{r}
mypop %>% 
  ggplot() + 
  geom_histogram(aes(x = height, fill = gender), col = "white",  alpha = 0.6, position = "identity") + 
  geom_vline(xintercept = pop_mu, col="red", lty = 2) + 
  theme_light()
```

Suppose also that I do not have money to cover the full population, so the best I can do is to interview 30 people. So I'll use their mean height to estimate the mean of the population.  

What I can do in my simulation (and that I cannot do in my real life) is to ask myself how **variable** is my estimation of the population mean when I repeat the sampling several times


## Simple Random Sampling
suppose that I have no clue about the presence of the two sub-populations, so the best I can do to avoid biases is **simple random sampling**. Remember, *random* is my best way to avoid introducing biases

So let's now simulate repeatedly the extraction of 30 people from my population and to see the variability of the process I do it 500 times

```{r}
## start creating the tibble container
x <- tibble(sampid = paste0("s",1:500))
head(x)
```

```{r}
## here we do the complete random sampling ...
x <- x %>% 
  mutate(random_samples = map(sampid, ~sample(x = mypop$height,size = 30)))
head(x)
```


```{r}
## now we calculate the averages
x <- x %>% 
  mutate(random_averages = map_dbl(random_samples, ~mean(.x)))
head(x)
```

And we plot the distribution of the estimates as a reference with the true population mean

```{r}
x %>% 
  ggplot() + 
  geom_point(aes(x = sampid, y = random_averages)) + 
  geom_hline(yintercept = pop_mu, col = "red", lty = 2) + 
  theme_light() + 
  theme(axis.text.x = element_blank())
```
The same plot as a histogram ...

```{r}
x %>% 
  ggplot() + 
  geom_histogram(aes(x = random_averages), alpha = 0.5, col = "white") + 
  geom_vline(xintercept = pop_mu, col = "red", lty = 2) + 
  theme_light()
```

As we can see, the estimate has variance (:-P), and it is centred around the correct value for the population mean. It is also normally distributed, but this you already know from the previous practical ...

## Stratified sampling

Suppose now that I'm aware of the fact that my population is composed by different subgroups. To take into account that I switch to **stratified random sampling**


If I'm sticking with 30 people I have to allocate them to the two groups in a proportion that mirrors the proportions of the individuals in the population

```{r}
nsamp <- 30

## here I calculate the fraction
subfractions <- ceiling((table(mypop$gender)/nrow(mypop))*nsamp)

## just to show how much easy to read is the coding with pipes
library(magrittr)

another_subfraction <- mypop$gender %>% 
  table(.) %>% 
  divide_by(nrow(mypop)) %>% 
  multiply_by(nsamp) %>% 
  ceiling(.)

subfractions
```

Just to check let's look to the proportions

```{r}
subfractions[1]/subfractions[2]
2000/8000
```

Let's now code this new way of sampling


```{r}
## here we do the complete random sampling of the two populations
## and we return a vector with the samples extracted in a stratified way
x <- x %>% 
  mutate(stratified_random_samples = map(sampid, function(n) {
    out_males <- mypop %>% filter(gender == "M") %>% pull(height) %>% sample(.,subfractions["M"])
    out_females <- mypop %>% filter(gender == "F") %>% pull(height) %>% sample(.,subfractions["F"])
    return(c(out_males,out_females))
  }))
head(x)
```

Now, the average of the samples will be another time the estimate of the population mean

```{r}
## now we calculate the averages
x <- x %>% 
  mutate(stratified_averages = map_dbl(stratified_random_samples, ~mean(.x)))
head(x)
```

And now we plot!

```{r}
x %>% 
  ggplot() + 
  geom_point(aes(x = sampid, y = random_averages), col = "steelblue", alpha = 0.5) + 
  geom_point(aes(x = sampid, y = stratified_averages), col = "orange", alpha = 0.5) + 
  geom_hline(yintercept = pop_mu, col = "red", lty = 2) + 
  theme_light() + 
  theme(axis.text.x = element_blank())
```
As before in terms of a histogram

```{r}
x %>% 
  ggplot() + 
  geom_histogram(aes(x = random_averages), fill = "blue", alpha = 0.5, col = "white") + 
  geom_histogram(aes(x = stratified_averages), fill = "red", alpha = 0.5, col = "white") + 
  geom_vline(xintercept = pop_mu, col = "red", lty = 2) + 
  theme_light()
```


As you can see the average is still good, but the _variability (variance) of my estimate is much smaller_
This is true for all the statistics you would like to estimate from your sample. If you think to it, the reason for this fact is that using stratification we ensure that our sample is representative of both subpopulations.

For our metabolomics business knowing this is important when you are dealing with observational studies. Because with experiment you are in general allocating experimental units as you want.


**Something for You**

* Check what happens to the two types of sampling if you change the unbalancing in the population ? 
* Check what happens to the two types of sampling if you change the size of the sample (here 30)?


Both tasks can be dealt either by changing my code above and looking to the results or everything can be organized in a more "scientific" way by calculating the variance of the estimates and wrapping the code in some sort of loop which will allow you to conveniently show your results in a plot.  






